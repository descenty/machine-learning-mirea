**Домашнее задание 1:** реализуйте XOR с помощью 3 нейронов. Запишите ответ в виде выражения, состоящего из объектов neuron() – моделей нейрона с пороговой функцией активации, внутри скобок может быть что угодно. Входы верхнего уровня называются x1 и x2. Пример фрагмента записи: neuron(1*x1 + 5*x2 - 0.1) + neuron(x1) (ответ будет выглядеть чуть сложнее, но других символов вроде && не потребуется).

### neuron(neuron(1x1 + 1x2) - neuron(1x1 + 1x2 - 1))

**Домашнее задание 2:** нарисуйте backward граф для выражения `a*b+c*d`. [Теория и пример оформления](https://www.youtube.com/watch?v=MswxJw-8PvE). Сравните полученные теоретические значения с аттрибутами grad у исходных тензоров.

### https://drive.google.com/file/d/1DQYr5sWAkpJEcF-Uq0SeUmkYiU4UC_ov/view?usp=sharing

**Домашнее задание 3:** Поэксперементируйте с размером тензоров, которые влезут на видеоркарту в Colab. Найдите максимальный размер тензора для типа данных float32, float64, float16, int32, int64. На сколько они отличаются.

![float16](https://user-images.githubusercontent.com/28193504/205499613-0ca8c095-d656-440c-a47f-5b046fa66c8b.png)
### Максимальные размеры тензоров для различных типов данных отличаются настолько, насколько больше требуется битов для хранения типов данных

**Домашнее задание 4:** Напишите хороший пример неэффективного кода для занятия памяти видеокарты, который вызовет ошибку out of memory

![image](https://user-images.githubusercontent.com/28193504/205500970-465deb73-de8b-44cf-b18c-2254cd9763f7.png)

**Домашнее задание 5:** Используя один линейный слой `nn.Linear` и один входной тензор `x` подберите подберите размерности так, чтобы занимать всю видеопамять.
Попробуйте применить линейный слой к тензору `x`. Что произойдет? Кратко опишите ваши эксперименты. Что вы поняли?
